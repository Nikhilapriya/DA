{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-05T06:26:14.367801Z","iopub.execute_input":"2021-12-05T06:26:14.368209Z","iopub.status.idle":"2021-12-05T06:26:14.379919Z","shell.execute_reply.started":"2021-12-05T06:26:14.368156Z","shell.execute_reply":"2021-12-05T06:26:14.378903Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". format(sys.version))\n\nimport pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\nprint(\"pandas version: {}\". format(pd.__version__))\n\nimport matplotlib #collection of functions for scientific and publication-ready visualization\nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\n\nimport numpy as np #foundational package for scientific computing\nprint(\"NumPy version: {}\". format(np.__version__))\n\nimport scipy as sp #collection of functions for scientific computing and advance mathematics\nprint(\"SciPy version: {}\". format(sp.__version__)) \n\nimport IPython\nfrom IPython import display #pretty printing of dataframes in Jupyter notebook\nprint(\"IPython version: {}\". format(IPython.__version__)) \n\nimport sklearn #collection of machine learning algorithms\nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\n\n#misc libraries\nimport random\nimport time\n\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nprint('-'*25)\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/titanic\"]).decode(\"utf8\"))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.381749Z","iopub.execute_input":"2021-12-05T06:26:14.382607Z","iopub.status.idle":"2021-12-05T06:26:14.418421Z","shell.execute_reply.started":"2021-12-05T06:26:14.382563Z","shell.execute_reply":"2021-12-05T06:26:14.417558Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix\n\n#Configure Visualization Defaults\n#%matplotlib inline = show plots in Jupyter Notebook browser\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.419743Z","iopub.execute_input":"2021-12-05T06:26:14.420022Z","iopub.status.idle":"2021-12-05T06:26:14.434495Z","shell.execute_reply.started":"2021-12-05T06:26:14.419989Z","shell.execute_reply":"2021-12-05T06:26:14.433500Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#import data\ndata_raw = pd.read_csv('../input/titanic/train.csv')\ndata_val  = pd.read_csv('../input/titanic/test.csv')\n\ndata1 = data_raw.copy(deep = True)\ndata_cleaner = [data1, data_val]\n\nprint (data_raw.info())\ndata_raw.sample(10) ","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.436515Z","iopub.execute_input":"2021-12-05T06:26:14.437028Z","iopub.status.idle":"2021-12-05T06:26:14.492059Z","shell.execute_reply.started":"2021-12-05T06:26:14.436987Z","shell.execute_reply":"2021-12-05T06:26:14.491166Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print('Train columns with null values:\\n', data1.isnull().sum())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values:\\n', data_val.isnull().sum())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.493992Z","iopub.execute_input":"2021-12-05T06:26:14.494572Z","iopub.status.idle":"2021-12-05T06:26:14.548560Z","shell.execute_reply.started":"2021-12-05T06:26:14.494522Z","shell.execute_reply":"2021-12-05T06:26:14.547706Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#Complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:    \n    #complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n    #complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n\n    #complete missing fare with median\n    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)\n    \n#delete the cabin feature/column and others previously stated to exclude in train dataset\ndrop_column = ['PassengerId','Cabin', 'Ticket']\ndata1.drop(drop_column, axis=1, inplace = True)\n\nprint(data1.isnull().sum())\nprint(\"-\"*10)\nprint(data_val.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.550099Z","iopub.execute_input":"2021-12-05T06:26:14.550717Z","iopub.status.idle":"2021-12-05T06:26:14.569490Z","shell.execute_reply.started":"2021-12-05T06:26:14.550671Z","shell.execute_reply":"2021-12-05T06:26:14.568410Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:    \n    #Discrete variables\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #initialize to 1 if he/she is alone\n    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # if family size is greater than 1\n    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n\n    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n\nstat_min = 10 \ntitle_names = (data1['Title'].value_counts() < stat_min) \n\ndata1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\nprint(data1['Title'].value_counts())\nprint(\"-\"*10)\n\n#display the data\ndata1.info()\ndata_val.info()\ndata1.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.571040Z","iopub.execute_input":"2021-12-05T06:26:14.571363Z","iopub.status.idle":"2021-12-05T06:26:14.668670Z","shell.execute_reply.started":"2021-12-05T06:26:14.571316Z","shell.execute_reply":"2021-12-05T06:26:14.667893Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#Convert objects to category using Label Encoder for train and test/validation dataset\nlabel = LabelEncoder()\nfor dataset in data_cleaner:    \n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n\n#define target variable \nTarget = ['Survived']\n\n#define x variables for original features\ndata1_x = ['Sex','Pclass', 'Embarked', 'Title','SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] #pretty name/values for charts\ndata1_x_calc = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code','SibSp', 'Parch', 'Age', 'Fare'] #coded for algorithm calculation\ndata1_xy =  Target + data1_x\nprint('Original X Y: ', data1_xy, '\\n')\n\n#define x variables for original w/bin features\ndata1_x_bin = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\ndata1_xy_bin = Target + data1_x_bin\nprint('Bin X Y: ', data1_xy_bin, '\\n')\n\n#define x and y variables for dummy features original\ndata1_dummy = pd.get_dummies(data1[data1_x])\ndata1_x_dummy = data1_dummy.columns.tolist()\ndata1_xy_dummy = Target + data1_x_dummy\nprint('Dummy X Y: ', data1_xy_dummy, '\\n')\n\n\n\ndata1_dummy.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.669816Z","iopub.execute_input":"2021-12-05T06:26:14.670062Z","iopub.status.idle":"2021-12-05T06:26:14.725295Z","shell.execute_reply.started":"2021-12-05T06:26:14.670022Z","shell.execute_reply":"2021-12-05T06:26:14.724583Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"print('Train columns with null values: \\n', data1.isnull().sum())\nprint(\"-\"*10)\nprint (data1.info())\nprint(\"-\"*10)\n\nprint('Test/Validation columns with null values: \\n', data_val.isnull().sum())\nprint(\"-\"*10)\nprint (data_val.info())\nprint(\"-\"*10)\n\ndata_raw.describe(include = 'all')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.726545Z","iopub.execute_input":"2021-12-05T06:26:14.726800Z","iopub.status.idle":"2021-12-05T06:26:14.807699Z","shell.execute_reply.started":"2021-12-05T06:26:14.726758Z","shell.execute_reply":"2021-12-05T06:26:14.806804Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#split train and test data with function defaults\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntrain1_x_bin, test1_x_bin, train1_y_bin, test1_y_bin = model_selection.train_test_split(data1[data1_x_bin], data1[Target] , random_state = 0)\ntrain1_x_dummy, test1_x_dummy, train1_y_dummy, test1_y_dummy = model_selection.train_test_split(data1_dummy[data1_x_dummy], data1[Target], random_state = 0)\n\nprint(\"Data1 Shape: {}\".format(data1.shape))\nprint(\"Train1 Shape: {}\".format(train1_x.shape))\nprint(\"Test1 Shape: {}\".format(test1_x.shape))\n\ntrain1_x_bin.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.810589Z","iopub.execute_input":"2021-12-05T06:26:14.810967Z","iopub.status.idle":"2021-12-05T06:26:14.841133Z","shell.execute_reply.started":"2021-12-05T06:26:14.810931Z","shell.execute_reply":"2021-12-05T06:26:14.840393Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#Discrete Variable Correlation by Survival using\nfor x in data1_x:\n    if data1[x].dtype != 'float64' :\n        print('Survival Correlation by:', x)\n        print(data1[[x, Target[0]]].groupby(x, as_index=False).mean())\n        print('-'*10, '\\n')\n\nprint(pd.crosstab(data1['Title'],data1[Target[0]]))","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.842045Z","iopub.execute_input":"2021-12-05T06:26:14.842279Z","iopub.status.idle":"2021-12-05T06:26:14.912741Z","shell.execute_reply.started":"2021-12-05T06:26:14.842252Z","shell.execute_reply":"2021-12-05T06:26:14.911793Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"#graph distribution of quantitative data\nplt.figure(figsize=[16,12])\n\nplt.subplot(231)\nplt.boxplot(x=data1['Fare'], showmeans = True, meanline = True)\nplt.title('Fare Boxplot')\nplt.ylabel('Fare ($)')\n\nplt.subplot(232)\nplt.boxplot(data1['Age'], showmeans = True, meanline = True)\nplt.title('Age Boxplot')\nplt.ylabel('Age (Years)')\n\nplt.subplot(233)\nplt.boxplot(data1['FamilySize'], showmeans = True, meanline = True)\nplt.title('Family Size Boxplot')\nplt.ylabel('Family Size (#)')\n\nplt.subplot(234)\nplt.hist(x = [data1[data1['Survived']==1]['Fare'], data1[data1['Survived']==0]['Fare']], \n         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Fare Histogram by Survival')\nplt.xlabel('Fare ($)')\nplt.ylabel('# of Passengers')\nplt.legend()\n\nplt.subplot(235)\nplt.hist(x = [data1[data1['Survived']==1]['Age'], data1[data1['Survived']==0]['Age']], \n         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Age Histogram by Survival')\nplt.xlabel('Age (Years)')\nplt.ylabel('# of Passengers')\nplt.legend()\n\nplt.subplot(236)\nplt.hist(x = [data1[data1['Survived']==1]['FamilySize'], data1[data1['Survived']==0]['FamilySize']], \n         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Family Size Histogram by Survival')\nplt.xlabel('Family Size (#)')\nplt.ylabel('# of Passengers')\nplt.legend()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:14.914857Z","iopub.execute_input":"2021-12-05T06:26:14.915075Z","iopub.status.idle":"2021-12-05T06:26:16.406989Z","shell.execute_reply.started":"2021-12-05T06:26:14.915049Z","shell.execute_reply":"2021-12-05T06:26:16.405931Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived', order=[1,2,3], data=data1, ax = saxis[0,1])\nsns.barplot(x = 'IsAlone', y = 'Survived', order=[1,0], data=data1, ax = saxis[0,2])\n\nsns.pointplot(x = 'FareBin', y = 'Survived',  data=data1, ax = saxis[1,0])\nsns.pointplot(x = 'AgeBin', y = 'Survived',  data=data1, ax = saxis[1,1])\nsns.pointplot(x = 'FamilySize', y = 'Survived', data=data1, ax = saxis[1,2])","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:16.408585Z","iopub.execute_input":"2021-12-05T06:26:16.409423Z","iopub.status.idle":"2021-12-05T06:26:18.262017Z","shell.execute_reply.started":"2021-12-05T06:26:16.409384Z","shell.execute_reply":"2021-12-05T06:26:18.261134Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#graph distribution of qualitative data: Pclass\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fare Survival Comparison')\n\nsns.violinplot(x = 'Pclass', y = 'Age', hue = 'Survived', data = data1, split = True, ax = axis2)\naxis2.set_title('Pclass vs Age Survival Comparison')\n\nsns.boxplot(x = 'Pclass', y ='FamilySize', hue = 'Survived', data = data1, ax = axis3)\naxis3.set_title('Pclass vs Family Size Survival Comparison')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:18.263345Z","iopub.execute_input":"2021-12-05T06:26:18.264218Z","iopub.status.idle":"2021-12-05T06:26:19.219270Z","shell.execute_reply.started":"2021-12-05T06:26:18.264157Z","shell.execute_reply":"2021-12-05T06:26:19.218390Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"#graph distribution of qualitative data: Sex\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Comparison')\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Pclass', data=data1, ax  = qaxis[1])\naxis1.set_title('Sex vs Pclass Survival Comparison')\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'IsAlone', data=data1, ax  = qaxis[2])\naxis1.set_title('Sex vs IsAlone Survival Comparison')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:19.220835Z","iopub.execute_input":"2021-12-05T06:26:19.221308Z","iopub.status.idle":"2021-12-05T06:26:20.408370Z","shell.execute_reply.started":"2021-12-05T06:26:19.221262Z","shell.execute_reply":"2021-12-05T06:26:20.407522Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"], ax = maxis1)\n\n#how does class factor with sex & survival compare\nsns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"], ax = maxis2)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:20.409920Z","iopub.execute_input":"2021-12-05T06:26:20.410798Z","iopub.status.idle":"2021-12-05T06:26:21.830113Z","shell.execute_reply.started":"2021-12-05T06:26:20.410751Z","shell.execute_reply":"2021-12-05T06:26:21.829208Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"#how does embark port factor with class, sex, and survival compare\ne = sns.FacetGrid(data1, col = 'Embarked')\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:21.831486Z","iopub.execute_input":"2021-12-05T06:26:21.831782Z","iopub.status.idle":"2021-12-05T06:26:23.424343Z","shell.execute_reply.started":"2021-12-05T06:26:21.831749Z","shell.execute_reply":"2021-12-05T06:26:23.423674Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#plot distributions of age of passengers who survived or did not survive\na = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:23.425603Z","iopub.execute_input":"2021-12-05T06:26:23.426067Z","iopub.status.idle":"2021-12-05T06:26:24.054422Z","shell.execute_reply.started":"2021-12-05T06:26:23.426027Z","shell.execute_reply":"2021-12-05T06:26:24.053275Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#histogram comparison of sex, class, and age by survival\nh = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:24.056141Z","iopub.execute_input":"2021-12-05T06:26:24.056494Z","iopub.status.idle":"2021-12-05T06:26:26.242639Z","shell.execute_reply.started":"2021-12-05T06:26:24.056447Z","shell.execute_reply":"2021-12-05T06:26:26.241661Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"#pair plots of entire dataset\npp = sns.pairplot(data1, hue = 'Survived', palette = 'deep', size=1.2, diag_kind = 'kde', diag_kws=dict(shade=True), plot_kws=dict(s=10) )\npp.set(xticklabels=[])","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:26:26.244076Z","iopub.execute_input":"2021-12-05T06:26:26.244450Z","iopub.status.idle":"2021-12-05T06:27:12.318929Z","shell.execute_reply.started":"2021-12-05T06:26:26.244387Z","shell.execute_reply":"2021-12-05T06:27:12.317973Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heatmap(data1)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:12.320165Z","iopub.execute_input":"2021-12-05T06:27:12.320510Z","iopub.status.idle":"2021-12-05T06:27:13.598354Z","shell.execute_reply.started":"2021-12-05T06:27:12.320475Z","shell.execute_reply":"2021-12-05T06:27:13.597488Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    \n    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n    XGBClassifier()    \n    ]\n\n\n\n#split dataset in cross-validation with this splitter\ncv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n\n#create table to compare MLA metrics\nMLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n#create table to compare MLA predictions\nMLA_predict = data1[Target]\n\n#index through MLA and save performance to table\nrow_index = 0\nfor alg in MLA:\n\n    #set name and parameters\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n    #score model with cross validation\n    cv_results = model_selection.cross_validate(alg, data1[data1_x_bin], data1[Target], cv  = cv_split ,return_train_score=True)\n    #print(cv_results)\n    \n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   \n    \n    alg.fit(data1[data1_x_bin], data1[Target])\n    MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n    \n    row_index+=1\n\n    \nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\nMLA_compare\n#MLA_predict\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:13.600218Z","iopub.execute_input":"2021-12-05T06:27:13.600584Z","iopub.status.idle":"2021-12-05T06:27:32.119238Z","shell.execute_reply.started":"2021-12-05T06:27:13.600538Z","shell.execute_reply":"2021-12-05T06:27:32.118518Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"#barplot \nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:32.120472Z","iopub.execute_input":"2021-12-05T06:27:32.120710Z","iopub.status.idle":"2021-12-05T06:27:32.668248Z","shell.execute_reply.started":"2021-12-05T06:27:32.120681Z","shell.execute_reply":"2021-12-05T06:27:32.667477Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"#group by or pivot table\npivot_female = data1[data1.Sex=='female'].groupby(['Sex','Pclass', 'Embarked','FareBin'])['Survived'].mean()\nprint('Survival Decision Tree w/Female Node: \\n',pivot_female)\n\npivot_male = data1[data1.Sex=='male'].groupby(['Sex','Title'])['Survived'].mean()\nprint('\\n\\nSurvival Decision Tree w/Male Node: \\n',pivot_male)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:32.669359Z","iopub.execute_input":"2021-12-05T06:27:32.669586Z","iopub.status.idle":"2021-12-05T06:27:32.696984Z","shell.execute_reply.started":"2021-12-05T06:27:32.669559Z","shell.execute_reply":"2021-12-05T06:27:32.695862Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#Plot Accuracy Summary\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Compute confusion matrix\ncnf_matrix = metrics.confusion_matrix(data1['Survived'], Tree_Predict)\nnp.set_printoptions(precision=2)\n\nclass_names = ['Dead', 'Survived']\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, \n                      title='Normalized confusion matrix')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:32.698224Z","iopub.execute_input":"2021-12-05T06:27:32.698477Z","iopub.status.idle":"2021-12-05T06:27:33.487574Z","shell.execute_reply.started":"2021-12-05T06:27:32.698449Z","shell.execute_reply":"2021-12-05T06:27:33.486611Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"#base model\ndtree = tree.DecisionTreeClassifier(random_state = 0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv  = cv_split,return_train_score=True)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('BEFORE DT Parameters: ', dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\nparam_grid = {'criterion': ['gini', 'entropy'], \n              'max_depth': [2,4,6,8,10,None], \n              'random_state': [0]\n             }\n\ntune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split,return_train_score=True)\ntune_model.fit(data1[data1_x_bin], data1[Target])\n\nprint('AFTER DT Parameters: ', tune_model.best_params_)\nprint(\"AFTER DT Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \nprint(\"AFTER DT Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\nprint(\"AFTER DT Test w/bin score 3*std: +/- {:.2f}\". format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\nprint('-'*10)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:33.488785Z","iopub.execute_input":"2021-12-05T06:27:33.489037Z","iopub.status.idle":"2021-12-05T06:27:35.059241Z","shell.execute_reply.started":"2021-12-05T06:27:33.489008Z","shell.execute_reply":"2021-12-05T06:27:35.058281Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"#TUNE MODEL\n\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n\n#feature selection\ndtree_rfe = feature_selection.RFECV(dtree, step = 1, scoring = 'accuracy', cv = cv_split)\ndtree_rfe.fit(data1[data1_x_bin], data1[Target])\n\n#transform x&y to reduced features and fit new model\nX_rfe = data1[data1_x_bin].columns.values[dtree_rfe.get_support()]\nrfe_results = model_selection.cross_validate(dtree, data1[X_rfe], data1[Target], cv  = cv_split,return_train_score=True)\n\nprint('AFTER DT RFE Training Shape New: ', data1[X_rfe].shape) \nprint('AFTER DT RFE Training Columns New: ', X_rfe)\n\nprint(\"AFTER DT RFE Training w/bin score mean: {:.2f}\". format(rfe_results['train_score'].mean()*100)) \nprint(\"AFTER DT RFE Test w/bin score mean: {:.2f}\". format(rfe_results['test_score'].mean()*100))\nprint(\"AFTER DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(rfe_results['test_score'].std()*100*3))\nprint('-'*10)\n\n\n#tune rfe model\nrfe_tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split,return_train_score=True)\nrfe_tune_model.fit(data1[X_rfe], data1[Target])\n\nprint('AFTER DT RFE Tuned Parameters: ', rfe_tune_model.best_params_)\nprint(\"AFTER DT RFE Tuned Training w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \nprint(\"AFTER DT RFE Tuned Test w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\nprint(\"AFTER DT RFE Tuned Test w/bin score 3*std: +/- {:.2f}\". format(rfe_tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\nprint('-'*10)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:35.060906Z","iopub.execute_input":"2021-12-05T06:27:35.061294Z","iopub.status.idle":"2021-12-05T06:27:36.759916Z","shell.execute_reply.started":"2021-12-05T06:27:35.061246Z","shell.execute_reply":"2021-12-05T06:27:36.758932Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"#Graph MLA version of Decision Tree\nimport graphviz \ndot_data = tree.export_graphviz(dtree, out_file=None, \n                                feature_names = data1_x_bin, class_names = True,\n                                filled = True, rounded = True)\ngraph = graphviz.Source(dot_data) \ngraph","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:36.764834Z","iopub.execute_input":"2021-12-05T06:27:36.765088Z","iopub.status.idle":"2021-12-05T06:27:36.915630Z","shell.execute_reply.started":"2021-12-05T06:27:36.765059Z","shell.execute_reply":"2021-12-05T06:27:36.914676Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"#compare algorithm predictions with each other\ncorrelation_heatmap(MLA_predict)","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:36.917474Z","iopub.execute_input":"2021-12-05T06:27:36.918379Z","iopub.status.idle":"2021-12-05T06:27:40.032655Z","shell.execute_reply.started":"2021-12-05T06:27:36.918332Z","shell.execute_reply":"2021-12-05T06:27:40.031737Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"vote_est = [\n    #Ensemble Methods\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassifier()),\n    ('gbc', ensemble.GradientBoostingClassifier()),\n    ('rfc', ensemble.RandomForestClassifier()),\n\n    #Gaussian Processes\n    ('gpc', gaussian_process.GaussianProcessClassifier()),\n    \n    #GLM\n    ('lr', linear_model.LogisticRegressionCV()),\n    \n    #Navies Bayes\n    ('bnb', naive_bayes.BernoulliNB()),\n    ('gnb', naive_bayes.GaussianNB()),\n    \n    #Nearest Neighbor\n    ('knn', neighbors.KNeighborsClassifier()),\n    \n    #SVM\n    ('svc', svm.SVC(probability=True)),\n    \n    #xgboost\n   ('xgb', XGBClassifier())\n\n]\n\n\n#Hard Vote or majority rules\nvote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\nvote_hard_cv = model_selection.cross_validate(vote_hard, data1[data1_x_bin], data1[Target], cv  = cv_split,  return_train_score=True)\nvote_hard.fit(data1[data1_x_bin], data1[Target])\n\nprint(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \nprint(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\nprint(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\nprint('-'*10)\n\n\n#Soft Vote or weighted probabilities\nvote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\nvote_soft_cv = model_selection.cross_validate(vote_soft, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score=True)\nvote_soft.fit(data1[data1_x_bin], data1[Target])\n\nprint(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \nprint(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\nprint(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\nprint('-'*10)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:27:40.034660Z","iopub.execute_input":"2021-12-05T06:27:40.035025Z","iopub.status.idle":"2021-12-05T06:28:16.114817Z","shell.execute_reply.started":"2021-12-05T06:27:40.034979Z","shell.execute_reply":"2021-12-05T06:28:16.113994Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"#prepare data for modeling\nprint(data_val.info())\nprint(\"-\"*10)\n\n\n\n#decision tree w/full dataset modeling submission score: defaults= 0.76555, tuned= 0.77990\n#submit_dt = tree.DecisionTreeClassifier()\n#submit_dt = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split)\n#submit_dt.fit(data1[data1_x_bin], data1[Target])\n#print('Best Parameters: ', submit_dt.best_params_) #Best Parameters:  {'criterion': 'gini', 'max_depth': 4, 'random_state': 0}\n#data_val['Survived'] = submit_dt.predict(data_val[data1_x_bin])\n\n\n#bagging w/full dataset modeling submission score: defaults= 0.75119, tuned= 0.77990\n#submit_bc = ensemble.BaggingClassifier()\n#submit_bc = model_selection.GridSearchCV(ensemble.BaggingClassifier(), param_grid= {'n_estimators':grid_n_estimator, 'max_samples': grid_ratio, 'oob_score': grid_bool, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n#submit_bc.fit(data1[data1_x_bin], data1[Target])\n#print('Best Parameters: ', submit_bc.best_params_) #Best Parameters:  {'max_samples': 0.25, 'n_estimators': 500, 'oob_score': True, 'random_state': 0}\n#data_val['Survived'] = submit_bc.predict(data_val[data1_x_bin])\n\n\n#extra tree w/full dataset modeling submission score: defaults= 0.76555, tuned= 0.77990\nsubmit_etc = ensemble.ExtraTreesClassifier()\nsubmit_etc = model_selection.GridSearchCV(ensemble.ExtraTreesClassifier(), param_grid={'n_estimators': grid_n_estimator, 'criterion': grid_criterion, 'max_depth': grid_max_depth, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\nsubmit_etc.fit(data1[data1_x_bin], data1[Target])\nprint('Best Parameters: ', submit_etc.best_params_) #Best Parameters:  {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0}\ndata_val['Survived'] = submit_etc.predict(data_val[data1_x_bin])\n\n\n#random foreset w/full dataset modeling submission score: defaults= 0.71291, tuned= 0.73205\n#submit_rfc = ensemble.RandomForestClassifier()\n#submit_rfc = model_selection.GridSearchCV(ensemble.RandomForestClassifier(), param_grid={'n_estimators': grid_n_estimator, 'criterion': grid_criterion, 'max_depth': grid_max_depth, 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n#submit_rfc.fit(data1[data1_x_bin], data1[Target])\n#print('Best Parameters: ', submit_rfc.best_params_) #Best Parameters:  {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'random_state': 0}\n#data_val['Survived'] = submit_rfc.predict(data_val[data1_x_bin])\n\n\n\n#ada boosting w/full dataset modeling submission score: defaults= 0.74162, tuned= 0.75119\n#submit_abc = ensemble.AdaBoostClassifier()\n#submit_abc = model_selection.GridSearchCV(ensemble.AdaBoostClassifier(), param_grid={'n_estimators': grid_n_estimator, 'learning_rate': grid_ratio, 'algorithm': ['SAMME', 'SAMME.R'], 'random_state': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n#submit_abc.fit(data1[data1_x_bin], data1[Target])\n#print('Best Parameters: ', submit_abc.best_params_) #Best Parameters:  {'algorithm': 'SAMME.R', 'learning_rate': 0.1, 'n_estimators': 300, 'random_state': 0}\n#data_val['Survived'] = submit_abc.predict(data_val[data1_x_bin])\n\n\n#gradient boosting w/full dataset modeling submission score: defaults= 0.75119, tuned= 0.77033\n#submit_gbc = ensemble.GradientBoostingClassifier()\n#submit_gbc = model_selection.GridSearchCV(ensemble.GradientBoostingClassifier(), param_grid={'learning_rate': grid_ratio, 'n_estimators': grid_n_estimator, 'max_depth': grid_max_depth, 'random_state':grid_seed}, scoring = 'roc_auc', cv = cv_split)\n#submit_gbc.fit(data1[data1_x_bin], data1[Target])\n#print('Best Parameters: ', submit_gbc.best_params_) #Best Parameters:  {'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 50, 'random_state': 0}\n#data_val['Survived'] = submit_gbc.predict(data_val[data1_x_bin])\n\n#extreme boosting w/full dataset modeling submission score: defaults= 0.73684, tuned= 0.77990\n#submit_xgb = XGBClassifier()\n#submit_xgb = model_selection.GridSearchCV(XGBClassifier(), param_grid= {'learning_rate': grid_learn, 'max_depth': [0,2,4,6,8,10], 'n_estimators': grid_n_estimator, 'seed': grid_seed}, scoring = 'roc_auc', cv = cv_split)\n#submit_xgb.fit(data1[data1_x_bin], data1[Target])\n#print('Best Parameters: ', submit_xgb.best_params_) #Best Parameters:  {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'seed': 0}\n#data_val['Survived'] = submit_xgb.predict(data_val[data1_x_bin])\n\n\n#hard voting classifier w/full dataset modeling submission score: defaults= 0.75598, tuned = 0.77990\n#data_val['Survived'] = vote_hard.predict(data_val[data1_x_bin])\n\n\n#soft voting classifier w/full dataset modeling submission score: defaults= 0.73684, tuned = 0.74162\n#data_val['Survived'] = vote_soft.predict(data_val[data1_x_bin])\n#data_val['Survived'] = grid_soft.predict(data_val[data1_x_bin])\n\n\n#submit file\nsubmit = data_val[['PassengerId','Survived']]\n#submit.to_csv(\"../working/submit.csv\", index=False)\n\n#print('Validation Data Distribution: \\n', data_val['Survived'].value_counts(normalize = True))\nsubmit\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T06:34:42.914343Z","iopub.execute_input":"2021-12-05T06:34:42.914905Z","iopub.status.idle":"2021-12-05T06:36:09.219033Z","shell.execute_reply.started":"2021-12-05T06:34:42.914873Z","shell.execute_reply":"2021-12-05T06:36:09.218103Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}